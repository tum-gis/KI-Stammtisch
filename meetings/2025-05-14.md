# KI-Stammtisch vom 14. März 2025

## Wie ChatGPT Dokumente liest: eine Einführung in Embeddings
Zentrales Thema dieser Session des KI-Stammtisches der Young-Professionals des Runden Tisch GIS sind Embeddings, welche in Anwendungen wie Retrieval Augmented Generation (RAG) eine Schlüsselrolle einnehmen. 
In diesem Tutorial wird die lokale Erzeugung von Embeddings und deren Verwendung in Kombination mit einer Vektordatenbank demonstriert.

![KI-Stammtisch2-800x379](https://github.com/user-attachments/assets/d99eef63-865f-4db1-baf9-2ca9b06b0c09)

## Voraussetzungen
### Grafikkarte
Für die Durchführung dieses Softwaretutorials benötigen sie idealerweise Zugang zu einer modernen Grafikkarte. Da Embedding Modelle im Vergelich mit anderen Modellen in der Regel weniger Parameter besitzen, ist für dieses Tutorial schon ein verhältnismäßig kleine Grafikkarte ausreichend.
### Betriebssystem
Dieses Software Tutorial wurde unter Ubuntu 22.04 konzipiert und getestet. Grunsätzlich sind die präsentierten Konzepte jedoch auch auf Windows übertragbar.
### Open Source Produkte
Für die Durchführung dieses Tutorials wird die folgende Open-Source-Software benötigt:
- [Ollama Standalone](https://ollama.com/)
- [Milvus](https://milvus.io/)
- [Python 3.12](https://www.python.org/downloads/release/python-3120/)
### Python Libraries
- [Ollama Python Library](https://github.com/ollama/ollama-python)
- [PyMilvus](https://github.com/milvus-io/pymilvus)
### Optional
- [PyCharm](https://www.jetbrains.com/pycharm/)

## Erstellen einfacher Embeddings
Zuerst muss die [Ollama Installation](https://ollama.com/download/linux) abgelschlossen, und anschließend das gewünschte Embedding Modell gepulled werden. 

```cmd
ollama pull <insert-model-name>
```
Anschließend können Sie das entsprechende Modell mit Hilfe der Milvus Python Library in Ihrem Python Code verwenden.

```python
import ollama

# The text that we would like to embed
text = "<your-text-example-here>"

# Performing the actual Embedding itself:
emb_1 = ollama.embed(model="<insert-model-name>", input=text)

# Printing out the embedding and metadata about it
print(f"type of emb_1: {type(emb_1)}")
print(f"emb_1:  {emb_1}")

# Zugriff auf das Embedding selbst
print(f"type of embedding 1: {type(emb_1['embeddings'])}")
print(f"Embeding dimensions: {len(emb_1['embeddings'][0])}")

```
     

## Aufsetzen einer Milvus Vektordatenbank
Der folgende Codeblock zum aufsetzen einer Milvus-Vektordatenbank entstammt der [offiziellen Milvus Dokumentation](https://milvus.io/docs/quickstart.md) und wurde für dieses Tutorial leicht überarbeitet.

Der Code Hilft Ihnen dabei, eine Milvus Datenbak aufzusetzen, mit welcher Sie Ihre Embedding Vektoren effizient speichern, verwalten, und fortgeschrittene Funktionen wie ANN-Search durchführen können.

```python
from pymilvus import MilvusClient, DataType

# Herstellen einer Verbindung zum lokal laufenden Milvus-Server her.
# Authentifizierung mit Nutzername root und Passwort Milvus.
client = MilvusClient(
    uri="http://localhost:19530",
    token="root:Milvus"
)

# Erstellen einer neuen Datenbank namens my_database_1
client.create_database(
    db_name="my_database_1"
)

# Erstellen eines Schemas zur Speicherung der Vektoren.
# auto_id=False: IDs werden manuell angegeben (nicht automatisch generiert).
# enable_dynamic_field=True: Ermöglicht das Speichern zusätzlicher dynamischer Felder (flexible Struktur).
schema = MilvusClient.create_schema(
    auto_id=False,
    enable_dynamic_field=True,
)

n = <ihre-gewünschte-embedding-length>

# Definiert zwei Felder:
#     my_id: Ganzzahlfeld (INT64), Primärschlüssel.
#     my_vector: Vektor-Feld mit n Dimensionen (FLOAT_VECTOR), für Embeddings.
schema.add_field(field_name="my_id", datatype=DataType.INT64, is_primary=True)
schema.add_field(field_name="my_vector", datatype=DataType.FLOAT_VECTOR, dim=n)

# Erstellt eine leere Indexkonfiguration, die später für Felder mit Indexen befüllt wird.
index_params = client.prepare_index_params()

# Erstellt einen automatischen Index für das my_id-Feld (z. B. für effiziente ID-Suche).
index_params.add_index(
    field_name="my_id",
    index_type="AUTOINDEX"
)

# Erstellen  eines automatischen Index für das Vektorfeld.
# metric_type="COSINE": Kosinus-Ähnlichkeit als metrik für den nearest-neighbour-search
index_params.add_index(
    field_name="my_vector",
    index_type="AUTOINDEX",
    metric_type="COSINE"  # This metric is later going to me used to conduct the nearest neighbourhood search
)

# Erstellen einer Collection namens "my_first_collection" mit dem definierten Schema und den Indizes.
# Die Indizes werden dabei direkt mitgeladen.
client.create_collection(
    collection_name="my_first_collection",
    schema=schema,
    index_params=index_params
)

```
Den nachfolgenden Codeblock können Sie verwenden, um 130 englische worte zu Embedden und die resultierenden Vektoren in der mit Hilfe des vorherigen Codeblocks vorbereiteten Milvus Datenbank zu speichern.

## Speichern von Embedding Vektoren in der Milvus Datenbank
```python
import ollama
from pymilvus import MilvusClient

# Herstellen einer Verbindung zum lokal laufenden Milvus-Server her.
# Authentifizierung mit Nutzername root und Passwort Milvus.
client = MilvusClient(
    uri="http://localhost:19530",
    token="root:Milvus"
)

# Liste von Beispielworten, erzeugt von ChatGPT
text_0 = "technology"
text_1 = "biology"
text_2 = "chemistry"
text_3 = "physics"
text_4 = "mathematics"
text_5 = "astronomy"
text_6 = "geography"
text_7 = "geology"
text_8 = "engineering"
text_9 = "robotics"
text_10 = "artificial"
text_11 = "intelligence"
text_12 = "neuroscience"
text_13 = "psychology"
text_14 = "sociology"
text_15 = "philosophy"
text_16 = "architecture"
text_17 = "design"
text_18 = "literature"
text_19 = "poetry"
text_20 = "grammar"
text_21 = "syntax"
text_22 = "semantics"
text_23 = "logic"
text_24 = "reasoning"
text_25 = "creativity"
text_26 = "emotion"
text_27 = "cognition"
text_28 = "computation"
text_29 = "simulation"
text_30 = "database"
text_31 = "network"
text_32 = "security"
text_33 = "cryptography"
text_34 = "algorithm"
text_35 = "programming"
text_36 = "coding"
text_37 = "python"
text_38 = "java"
text_39 = "javascript"
text_40 = "compiler"
text_41 = "processor"
text_42 = "hardware"
text_43 = "software"
text_44 = "cloud"
text_45 = "storage"
text_46 = "interface"
text_47 = "framework"
text_48 = "library"
text_49 = "function"
text_50 = "variable"
text_51 = "constant"
text_52 = "object"
text_53 = "class"
text_54 = "method"
text_55 = "module"
text_56 = "system"
text_57 = "machine"
text_58 = "learning"
text_59 = "training"
text_60 = "model"
text_61 = "dataset"
text_62 = "analysis"
text_63 = "statistics"
text_64 = "probability"
text_65 = "distribution"
text_66 = "regression"
text_67 = "clustering"
text_68 = "classification"
text_69 = "vision"
text_70 = "language"
text_71 = "translation"
text_72 = "recognition"
text_73 = "speech"
text_74 = "audio"
text_75 = "image"
text_76 = "video"
text_77 = "signal"
text_78 = "sensor"
text_79 = "actuator"
text_80 = "automation"
text_81 = "control"
text_82 = "feedback"
text_83 = "optimization"
text_84 = "calculus"
text_85 = "algebra"
text_86 = "geometry"
text_87 = "trigonometry"
text_88 = "equation"
text_89 = "theorem"
text_90 = "proof"
text_91 = "hypothesis"
text_92 = "experiment"
text_93 = "observation"
text_94 = "theory"
text_95 = "fact"
text_96 = "concept"
text_97 = "principle"
text_98 = "idea"
text_99 = "discipline"
text_100 = "empire"
text_101 = "dynasty"
text_102 = "revolution"
text_103 = "democracy"
text_104 = "treaty"
text_105 = "colonialism"
text_106 = "abolition"
text_107 = "constitution"
text_108 = "civilization"
text_109 = "migration"
text_110 = "painting"
text_111 = "sculpture"
text_112 = "canvas"
text_113 = "gallery"
text_114 = "portrait"
text_115 = "abstract"
text_116 = "ceramics"
text_117 = "sketch"
text_118 = "installation"
text_119 = "mural"
text_120 = "justice"
text_121 = "court"
text_122 = "trial"
text_123 = "verdict"
text_124 = "plaintiff"
text_125 = "defendant"
text_126 = "contract"
text_127 = "appeal"
text_128 = "legislation"
text_129 = "jurisdiction"

texts = [text_0, text_1, text_2, text_3, text_4, text_5, text_6, text_7, text_8, text_9,
         text_10, text_11, text_12, text_13, text_14, text_15, text_16, text_17, text_18, text_19,
         text_20, text_21, text_22, text_23, text_24, text_25, text_26, text_27, text_28, text_29,
         text_30, text_31, text_32, text_33, text_34, text_35, text_36, text_37, text_38, text_39,
         text_40, text_41, text_42, text_43, text_44, text_45, text_46, text_47, text_48, text_49,
         text_50, text_51, text_52, text_53, text_54, text_55, text_56, text_57, text_58, text_59,
         text_60, text_61, text_62, text_63, text_64, text_65, text_66, text_67, text_68, text_69,
         text_70, text_71, text_72, text_73, text_74, text_75, text_76, text_77, text_78, text_79,
         text_80, text_81, text_82, text_83, text_84, text_85, text_86, text_87, text_88, text_89,
         text_90, text_91, text_92, text_93, text_94, text_95, text_96, text_97, text_98, text_99,
         text_100, text_101, text_102, text_103, text_104, text_105, text_106, text_107, text_108, text_109,
         text_110, text_111, text_112, text_113, text_114, text_115, text_116, text_117, text_118, text_119,
         text_120, text_121, text_122, text_123, text_124, text_125, text_126, text_127, text_128, text_129]

# jedes wort wird individuell embedded und das embedding in der Vektordaetnbank gespeichert
for counter, text in enumerate(texts):
    print(counter)
    print(text)
    string_to_embed = "search_document: " + text # Prefix bei Verwendung eines anderen Modells entsprechend anpassen! 
    emb = ollama.embed(model="nomic-embed-text:v1.5", input=string_to_embed)
    embedding_vector = emb.model_dump()['embeddings'][0]
    print(embedding_vector)
    data = {"my_id": counter, "my_vector": embedding_vector}
    print(data)
    print(emb)

    # Speichern des vektors in der Datenbank
    res = client.insert(
        collection_name="my_first_collection",
        data=data
    )

    print(res)

```

## Nearest Neighbour Search
Diesen Codeblock können Sie verwenden, um eine einfache Vektorsuche auf Ihrere Milvus Datenbank auszuführen.

```python
from pymilvus import MilvusClient
import ollama

# Herstellen einer Verbindung zum lokal laufenden Milvus-Server her.
# Authentifizierung mit Nutzername root und Passwort Milvus.
client = MilvusClient(
    uri="http://localhost:19530",
    token="root:Milvus"
)

search_text = "<place-your-query-word-here"
string_to_embed = "search_query: " + search_text # Prefix bei Verwendung eines anderen Modells entsprechend anpassen!
emb = ollama.embed(model="nomic-embed-text:v1.5", input=string_to_embed)
query_vector = emb.model_dump()['embeddings'][0]

# Ausführen der Nearest-Neighbour-Suche
res = client.search(
    collection_name="my_first_collection",
    anns_field="my_vector",
    data=[query_vector],
    limit=3,  # Es werden nur die drei besten Ergebnisse berücksichtigt
    search_params={"metric_type": "COSINE"}
)

# Ausgabe der Ergebnisse
for hits in res:
    for hit in hits:
        print(hit)

```


